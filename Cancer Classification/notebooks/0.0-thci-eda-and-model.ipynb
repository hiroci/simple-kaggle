{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reading file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Cancer_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Type casting and cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 32',axis=1)\n",
    "df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0}).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    int8   \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), int8(1)\n",
      "memory usage: 138.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking for NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No duplicate ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 569)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id.nunique(), df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Features and target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['id','diagnosis'], axis=1)\n",
    "target = df['diagnosis']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classes Percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(target.value_counts(), labels=['Benign', 'Malignant'], autopct='%.0f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Removing outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_out_of_quantile(column):\n",
    "    lower = column.quantile(.1)\n",
    "    upper = column.quantile(.9)\n",
    "\n",
    "    column = column.where((column < upper) & (column > lower))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in features:\n",
    "    \n",
    "    column = features[column_name]\n",
    "\n",
    "    lower = column.quantile(.01)\n",
    "    upper = column.quantile(.99)\n",
    "\n",
    "    features[column_name] = column.where((column < upper) & (column > lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.dropna()\n",
    "target = target.iloc[features.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Removing low correlation features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_corr = df.corr()[2:]['diagnosis']\n",
    "top_features = feat_corr[(feat_corr > .1) | (feat_corr < -.1)]\n",
    "top_features = features.loc[:, top_features.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.2)\n",
    "X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(features, target, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        48\n",
      "           1       0.95      0.93      0.94        41\n",
      "\n",
      "    accuracy                           0.94        89\n",
      "   macro avg       0.94      0.94      0.94        89\n",
      "weighted avg       0.94      0.94      0.94        89\n",
      "\n",
      "10 Fold Cross validation mean f1 : 0.9497421798631477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=5,\n",
    "                            random_state=2049,\n",
    "                            class_weight='balanced')\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_pred=rf.predict(X_test), y_true=y_test))\n",
    "\n",
    "cv_results = cross_validate(rf, X=features, y=target, cv=10,scoring='f1')\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest top features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        59\n",
      "           1       0.94      0.97      0.95        30\n",
      "\n",
      "    accuracy                           0.97        89\n",
      "   macro avg       0.96      0.97      0.96        89\n",
      "weighted avg       0.97      0.97      0.97        89\n",
      "\n",
      "10 Fold Cross validation mean f1 : 0.9495711143695015\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=5,\n",
    "                            random_state=2049,\n",
    "                            class_weight='balanced')\n",
    "\n",
    "rf.fit(X_train_top, y_train_top)\n",
    "\n",
    "print(classification_report(y_pred=rf.predict(X_test_top), y_true=y_test_top))\n",
    "cv_results = cross_validate(rf, X=top_features, y=target, cv=10,scoring='f1')\n",
    "\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        48\n",
      "           1       1.00      0.98      0.99        41\n",
      "\n",
      "    accuracy                           0.99        89\n",
      "   macro avg       0.99      0.99      0.99        89\n",
      "weighted avg       0.99      0.99      0.99        89\n",
      "\n",
      "10 Fold Cross validation mean f1 : 0.9741739980449658\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "scale_pos_weight = (target == False).sum()/(target == True).sum()\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic',\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    n_estimators=100)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print(classification_report(y_true=y_test, y_pred=rf.predict(X_test)))\n",
    "\n",
    "cv_results = cross_validate(xgb, X=features, y=target, cv=10,scoring='f1')\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost top features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        59\n",
      "           1       0.94      0.97      0.95        30\n",
      "\n",
      "    accuracy                           0.97        89\n",
      "   macro avg       0.96      0.97      0.96        89\n",
      "weighted avg       0.97      0.97      0.97        89\n",
      "\n",
      "10 Fold Cross validation mean f1 : 0.9745906647116325\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective='binary:logistic',\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    n_estimators=100)\n",
    "\n",
    "xgb.fit(X_train_top, y_train_top)\n",
    "print(classification_report(y_true=y_test_top, y_pred=rf.predict(X_test_top)))\n",
    "\n",
    "cv_results = cross_validate(xgb, X=top_features, y=target, cv=10,scoring='f1')\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.2</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.4</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.2</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>14.05</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.04304</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.06171</td>\n",
       "      <td>...</td>\n",
       "      <td>15.30</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.2</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>20.92</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.14740</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.06879</td>\n",
       "      <td>...</td>\n",
       "      <td>24.29</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.1</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.1</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.7</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "5          12.45         15.70           82.57      477.1          0.12780   \n",
       "6          18.25         19.98          119.60     1040.0          0.09463   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "560        14.05         27.15           91.38      600.4          0.09929   \n",
       "563        20.92         25.09          143.00     1347.0          0.10990   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "5             0.17000         0.15780              0.08089         0.2087   \n",
       "6             0.10900         0.11270              0.07400         0.1794   \n",
       "..                ...             ...                  ...            ...   \n",
       "560           0.11260         0.04462              0.04304         0.1537   \n",
       "563           0.22360         0.31740              0.14740         0.2149   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "1                   0.05667  ...         24.99          23.41   \n",
       "2                   0.05999  ...         23.57          25.53   \n",
       "4                   0.05883  ...         22.54          16.67   \n",
       "5                   0.07613  ...         15.47          23.75   \n",
       "6                   0.05742  ...         22.88          27.66   \n",
       "..                      ...  ...           ...            ...   \n",
       "560                 0.06171  ...         15.30          33.17   \n",
       "563                 0.06879  ...         24.29          29.41   \n",
       "564                 0.05623  ...         25.45          26.40   \n",
       "565                 0.05533  ...         23.69          38.25   \n",
       "566                 0.05648  ...         18.98          34.12   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "1              158.8      1956.0            0.1238             0.1866   \n",
       "2              152.5      1709.0            0.1444             0.4245   \n",
       "4              152.2      1575.0            0.1374             0.2050   \n",
       "5              103.4       741.6            0.1791             0.5249   \n",
       "6              153.2      1606.0            0.1442             0.2576   \n",
       "..               ...         ...               ...                ...   \n",
       "560            100.2       706.7            0.1241             0.2264   \n",
       "563            179.1      1819.0            0.1407             0.4186   \n",
       "564            166.1      2027.0            0.1410             0.2113   \n",
       "565            155.0      1731.0            0.1166             0.1922   \n",
       "566            126.7      1124.0            0.1139             0.3094   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "5             0.5355                0.1741          0.3985   \n",
       "6             0.3784                0.1932          0.3063   \n",
       "..               ...                   ...             ...   \n",
       "560           0.1326                0.1048          0.2250   \n",
       "563           0.6599                0.2542          0.2929   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "4                    0.07678  \n",
       "5                    0.12440  \n",
       "6                    0.08368  \n",
       "..                       ...  \n",
       "560                  0.08321  \n",
       "563                  0.09873  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "\n",
       "[441 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.2</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.4</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.2</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>14.05</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.04304</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>...</td>\n",
       "      <td>15.30</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.2</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>20.92</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.14740</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>...</td>\n",
       "      <td>24.29</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.1</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.1</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.7</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "5          12.45         15.70           82.57      477.1          0.12780   \n",
       "6          18.25         19.98          119.60     1040.0          0.09463   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "560        14.05         27.15           91.38      600.4          0.09929   \n",
       "563        20.92         25.09          143.00     1347.0          0.10990   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "5             0.17000         0.15780              0.08089         0.2087   \n",
       "6             0.10900         0.11270              0.07400         0.1794   \n",
       "..                ...             ...                  ...            ...   \n",
       "560           0.11260         0.04462              0.04304         0.1537   \n",
       "563           0.22360         0.31740              0.14740         0.2149   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "\n",
       "     radius_se  ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "1       0.5435  ...         24.99          23.41            158.8      1956.0   \n",
       "2       0.7456  ...         23.57          25.53            152.5      1709.0   \n",
       "4       0.7572  ...         22.54          16.67            152.2      1575.0   \n",
       "5       0.3345  ...         15.47          23.75            103.4       741.6   \n",
       "6       0.4467  ...         22.88          27.66            153.2      1606.0   \n",
       "..         ...  ...           ...            ...              ...         ...   \n",
       "560     0.3645  ...         15.30          33.17            100.2       706.7   \n",
       "563     0.9622  ...         24.29          29.41            179.1      1819.0   \n",
       "564     1.1760  ...         25.45          26.40            166.1      2027.0   \n",
       "565     0.7655  ...         23.69          38.25            155.0      1731.0   \n",
       "566     0.4564  ...         18.98          34.12            126.7      1124.0   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "1              0.1238             0.1866           0.2416   \n",
       "2              0.1444             0.4245           0.4504   \n",
       "4              0.1374             0.2050           0.4000   \n",
       "5              0.1791             0.5249           0.5355   \n",
       "6              0.1442             0.2576           0.3784   \n",
       "..                ...                ...              ...   \n",
       "560            0.1241             0.2264           0.1326   \n",
       "563            0.1407             0.4186           0.6599   \n",
       "564            0.1410             0.2113           0.4107   \n",
       "565            0.1166             0.1922           0.3215   \n",
       "566            0.1139             0.3094           0.3403   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "5                  0.1741          0.3985                  0.12440  \n",
       "6                  0.1932          0.3063                  0.08368  \n",
       "..                    ...             ...                      ...  \n",
       "560                0.1048          0.2250                  0.08321  \n",
       "563                0.2542          0.2929                  0.09873  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "\n",
       "[441 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": [20, 60, 100],\n",
    "    \"max_depth\": [ 2, 5],\n",
    "    \"max_leaves\":[0, 2, 5],\n",
    "    \"learning_rate\":[.1, .01, .5],\n",
    "    \"verbosity\": [1],\n",
    "    \"objective\": ['binary:logistic'],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"scale_pos_weight\": [None, scale_pos_weight, np.sqrt(scale_pos_weight)]\n",
    "}\n",
    "grid = GridSearchCV(XGBClassifier(), \n",
    "                    param_grid=params,\n",
    "                    cv=10, \n",
    "                    scoring='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.5], 'max_depth': [2, 5],\n",
       "                         'max_leaves': [0, 2, 5], 'n_estimators': [20, 60, 100],\n",
       "                         'n_jobs': [-1], 'objective': ['binary:logistic'],\n",
       "                         'scale_pos_weight': [None, 1.7911392405063291,\n",
       "                                              1.3383345024717583],\n",
       "                         'verbosity': [1]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_top, y_train_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = XGBClassifier(**grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Fold Cross validation mean f1 : 0.9683406647116325\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(best_xgb, X=top_features, y=target, cv=10,scoring='f1')\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LightGBM all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        56\n",
      "           1       0.94      0.97      0.96        33\n",
      "\n",
      "    accuracy                           0.97        89\n",
      "   macro avg       0.96      0.97      0.96        89\n",
      "weighted avg       0.97      0.97      0.97        89\n",
      "\n",
      "10 Fold Cross validation mean f1 : 0.970733137829912\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(class_weight='balanced')\n",
    "\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=rf.predict(X_test)))\n",
    "\n",
    "cv_results = cross_validate(lgb, X=features, y=target, cv=10,scoring='f1')\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        59\n",
      "           1       0.88      0.93      0.90        30\n",
      "\n",
      "    accuracy                           0.93        89\n",
      "   macro avg       0.92      0.93      0.93        89\n",
      "weighted avg       0.93      0.93      0.93        89\n",
      "\n",
      "10 Fold Cross validation mean f1 : 0.9741665823979506\n"
     ]
    }
   ],
   "source": [
    "lgb.fit(X_train_top, y_train_top)\n",
    "\n",
    "print(classification_report(y_true=y_test_top, y_pred=rf.predict(X_test_top)))\n",
    "\n",
    "cv_results = cross_validate(lgb, X=top_features, y=target, cv=10,scoring='f1')\n",
    "print(f'10 Fold Cross validation mean f1 : {cv_results[\"test_score\"].mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
